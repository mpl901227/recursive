/**
 * LLM API Client
 * Claudeì™€ OpenAI APIë¥¼ ì§€ì›í•˜ëŠ” í†µí•© í´ë¼ì´ì–¸íŠ¸
 */
const axios = require('axios');

class LLMClient {
    constructor() {
        this.claudeApiKey = process.env.ANTHROPIC_API_KEY;
        this.openaiApiKey = process.env.OPENAI_API_KEY;
        
        // API ì—”ë“œí¬ì¸íŠ¸
        this.claudeEndpoint = 'https://api.anthropic.com/v1/messages';
        this.openaiEndpoint = 'https://api.openai.com/v1/chat/completions';
        
        // ê¸°ë³¸ ì„¤ì •
        this.defaultTimeout = 30000; // 30ì´ˆ
        this.maxRetries = 3;
    }

    /**
     * ëª¨ë¸ì— ë”°ë¼ ì ì ˆí•œ API í˜¸ì¶œ
     * @param {Object} params - ë§¤ê°œë³€ìˆ˜ ê°ì²´
     * @param {string} params.model - ì‚¬ìš©í•  ëª¨ë¸ëª…
     * @param {Array} params.messages - ë©”ì‹œì§€ ë°°ì—´
     * @param {number} params.max_tokens - ìµœëŒ€ í† í° ìˆ˜
     * @param {number} params.temperature - ì˜¨ë„ ì„¤ì •
     * @param {number} params.timeout - íƒ€ì„ì•„ì›ƒ
     */
    async chat(params) {
        // ë§¤ê°œë³€ìˆ˜ ì¶”ì¶œ ë° ê¸°ë³¸ê°’ ì„¤ì •
        const { 
            model, 
            messages, 
            max_tokens: maxTokens = 2000, 
            temperature = 0.7, 
            timeout = this.defaultTimeout 
        } = params;
        
        if (!model || !messages) {
            throw new Error('Model and messages are required parameters');
        }
        
        console.log('ğŸ”„ LLM API call with params:', { model, messageCount: messages.length, maxTokens });
        
        if (model.startsWith('claude')) {
            return await this.callClaude(model, messages, { temperature, maxTokens, timeout });
        } else if (model.startsWith('gpt')) {
            return await this.callOpenAI(model, messages, { temperature, maxTokens, timeout });
        } else {
            throw new Error(`Unsupported model: ${model}`);
        }
    }

    /**
     * Claude API í˜¸ì¶œ
     */
    async callClaude(model, messages, options = {}) {
        if (!this.claudeApiKey) {
            throw new Error('ANTHROPIC_API_KEY not found in environment variables');
        }

        const { temperature, maxTokens, timeout } = options;
        
        // ë©”ì‹œì§€ í¬ë§· ë³€í™˜ (Claude í˜•ì‹)
        const claudeMessages = this.convertToClaudeFormat(messages);
        
        const requestData = {
            model: this.mapClaudeModel(model),
            max_tokens: maxTokens,
            temperature,
            messages: claudeMessages
        };

        try {
            const response = await axios.post(this.claudeEndpoint, requestData, {
                headers: {
                    'Content-Type': 'application/json',
                    'x-api-key': this.claudeApiKey,
                    'anthropic-version': '2023-06-01'
                },
                timeout
            });

            return {
                success: true,
                content: response.data.content[0].text,
                usage: response.data.usage,
                model: response.data.model
            };
        } catch (error) {
            const errorDetails = {
                message: error.message,
                status: error.response?.status,
                statusText: error.response?.statusText,
                data: error.response?.data,
                requestData: requestData
            };
            console.error('ğŸš« Claude API error ìƒì„¸:', errorDetails);
            throw new Error(`Claude API error (${error.response?.status || 'unknown'}): ${error.response?.data?.error?.message || error.message}`);
        }
    }

    /**
     * OpenAI API í˜¸ì¶œ
     */
    async callOpenAI(model, messages, options = {}) {
        if (!this.openaiApiKey) {
            throw new Error('OPENAI_API_KEY not found in environment variables');
        }

        const { temperature, maxTokens, timeout } = options;
        
        const requestData = {
            model: this.mapOpenAIModel(model),
            messages: messages,
            temperature,
            max_tokens: maxTokens
        };

        try {
            const response = await axios.post(this.openaiEndpoint, requestData, {
                headers: {
                    'Content-Type': 'application/json',
                    'Authorization': `Bearer ${this.openaiApiKey}`
                },
                timeout
            });

            return {
                success: true,
                content: response.data.choices[0].message.content,
                usage: response.data.usage,
                model: response.data.model
            };
        } catch (error) {
            const errorDetails = {
                message: error.message,
                status: error.response?.status,
                statusText: error.response?.statusText,
                data: error.response?.data,
                requestData: requestData
            };
            console.error('ğŸš« OpenAI API error ìƒì„¸:', errorDetails);
            throw new Error(`OpenAI API error (${error.response?.status || 'unknown'}): ${error.response?.data?.error?.message || error.message}`);
        }
    }

    /**
     * ë©”ì‹œì§€ë¥¼ Claude í˜•ì‹ìœ¼ë¡œ ë³€í™˜
     */
    convertToClaudeFormat(messages) {
        return messages.map(msg => ({
            role: msg.role === 'system' ? 'user' : msg.role,
            content: msg.content
        }));
    }

    /**
     * Claude ëª¨ë¸ëª… ë§¤í•‘
     */
    mapClaudeModel(model) {
        const modelMap = {
            'claude-3.5-sonnet': 'claude-3-5-sonnet-20241022',
            'claude-3-haiku': 'claude-3-haiku-20240307',
            'claude-3-opus': 'claude-3-opus-20240229'
        };
        return modelMap[model] || model;
    }

    /**
     * OpenAI ëª¨ë¸ëª… ë§¤í•‘
     */
    mapOpenAIModel(model) {
        const modelMap = {
            'gpt-4': 'gpt-4-turbo-preview',
            'gpt-3.5-turbo': 'gpt-3.5-turbo'
        };
        return modelMap[model] || model;
    }

    /**
     * ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡
     */
    getAvailableModels() {
        const models = [];
        
        if (this.claudeApiKey) {
            models.push('claude-3.5-sonnet', 'claude-3-haiku', 'claude-3-opus');
        }
        
        if (this.openaiApiKey) {
            models.push('gpt-4', 'gpt-3.5-turbo');
        }
        
        return models;
    }

    /**
     * API í‚¤ ì„¤ì • ìƒíƒœ í™•ì¸
     */
    getStatus() {
        return {
            claude: !!this.claudeApiKey,
            openai: !!this.openaiApiKey,
            availableModels: this.getAvailableModels()
        };
    }
}

module.exports = LLMClient; 