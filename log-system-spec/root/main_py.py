#!/usr/bin/env python3
"""
í†µí•© ë¡œê·¸ ìˆ˜ì§‘ê¸° - CLI ë©”ì¸ ì§„ì…ì 
ê°œë°œìë¥¼ ìœ„í•œ ì›í´ë¦­ ë¡œê·¸ ìˆ˜ì§‘ ì‹œìŠ¤í…œ
"""

import asyncio
import sys
import os
import signal
import argparse
import subprocess
import time
import json
import yaml
from pathlib import Path
from typing import Dict, List, Optional
from datetime import datetime

# ë¡œì»¬ ëª¨ë“ˆ ì„í¬íŠ¸
try:
    from server import LogCollectorServer
    from collectors import CollectorManager
    from storage import create_storage, migrate_database
    from config import Config, create_default_config
except ImportError as e:
    print(f"ëª¨ë“ˆ ì„í¬íŠ¸ ì˜¤ë¥˜: {e}")
    print("í˜„ì¬ ë””ë ‰í† ë¦¬ì—ì„œ ì‹¤í–‰í•˜ê±°ë‚˜ PYTHONPATHë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    sys.exit(1)


class LogCollectorCLI:
    """ë©”ì¸ CLI í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.config = None
        self.server_process = None
        self.collector_manager = None
        self.running_processes = []
        
    def setup_signal_handlers(self):
        """ì‹œê·¸ë„ í•¸ë“¤ëŸ¬ ì„¤ì •"""
        def signal_handler(signum, frame):
            print(f"\nì‹œê·¸ë„ {signum} ìˆ˜ì‹ , ì¢…ë£Œ ì¤‘...")
            asyncio.create_task(self.cleanup())
            
        signal.signal(signal.SIGINT, signal_handler)
        signal.signal(signal.SIGTERM, signal_handler)
        
    async def cleanup(self):
        """ì •ë¦¬ ì‘ì—…"""
        print("ë¡œê·¸ ìˆ˜ì§‘ê¸° ì •ë¦¬ ì¤‘...")
        
        # ìˆ˜ì§‘ê¸° ì¤‘ì§€
        if self.collector_manager:
            await self.collector_manager.stop_all()
            
        # ì„œë²„ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ
        for proc in self.running_processes:
            if proc.poll() is None:
                proc.terminate()
                try:
                    proc.wait(timeout=5)
                except subprocess.TimeoutExpired:
                    proc.kill()
                    
        print("ì •ë¦¬ ì™„ë£Œ")
        
    def load_config(self, config_path: str = None) -> Config:
        """ì„¤ì • ë¡œë“œ"""
        if config_path and os.path.exists(config_path):
            self.config = Config.from_file(config_path)
        else:
            # ê¸°ë³¸ ì„¤ì • íŒŒì¼ ì°¾ê¸°
            default_paths = [
                "./log_collector.yaml",
                "./config/log_collector.yaml", 
                "~/.log_collector/config.yaml"
            ]
            
            for path in default_paths:
                expanded_path = os.path.expanduser(path)
                if os.path.exists(expanded_path):
                    self.config = Config.from_file(expanded_path)
                    print(f"ì„¤ì • íŒŒì¼ ë¡œë“œë¨: {expanded_path}")
                    break
            else:
                # ê¸°ë³¸ ì„¤ì • ìƒì„±
                self.config = Config()
                print("ê¸°ë³¸ ì„¤ì • ì‚¬ìš©")
                
        return self.config
        
    async def start_server(self, args):
        """ì„œë²„ ì‹œì‘"""
        print("=== ë¡œê·¸ ìˆ˜ì§‘ ì„œë²„ ì‹œì‘ ===")
        
        config = self.load_config(args.config)
        
        # ì„œë²„ ì„¤ì •
        host = args.host or config.server.host
        port = args.port or config.server.port
        db_path = args.db or config.storage.db_path
        
        # ì„œë²„ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        server = LogCollectorServer(host, port)
        server.storage = create_storage(
            db_path=db_path,
            max_size_mb=config.storage.max_size_mb,
            max_days=config.storage.max_days
        )
        
        print(f"ì„œë²„ ì£¼ì†Œ: http://{host}:{port}")
        print(f"ë°ì´í„°ë² ì´ìŠ¤: {db_path}")
        print(f"WebSocket: ws://{host}:{port}/ws")
        print(f"RPC ì—”ë“œí¬ì¸íŠ¸: http://{host}:{port}/rpc")
        
        try:
            await server.start()
            
            print("\nì„œë²„ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. Ctrl+Cë¡œ ì¢…ë£Œí•˜ì„¸ìš”.")
            
            # ì„œë²„ ìœ ì§€
            while True:
                await asyncio.sleep(1)
                
        except KeyboardInterrupt:
            print("\nì„œë²„ ì¢…ë£Œ ì¤‘...")
        except Exception as e:
            print(f"ì„œë²„ ì˜¤ë¥˜: {e}")
        finally:
            await self.cleanup()
            
    async def start_collectors(self, args):
        """ìˆ˜ì§‘ê¸° ì‹œì‘"""
        print("=== ë¡œê·¸ ìˆ˜ì§‘ê¸° ì‹œì‘ ===")
        
        config = self.load_config(args.config)
        
        # ìˆ˜ì§‘ê¸° ê´€ë¦¬ì ìƒì„±
        self.collector_manager = CollectorManager(args.config)
        
        # ì„ íƒëœ ìˆ˜ì§‘ê¸°ë“¤
        selected_collectors = args.collectors or None
        
        if selected_collectors:
            print(f"ì‹œì‘í•  ìˆ˜ì§‘ê¸°: {', '.join(selected_collectors)}")
        else:
            print("ëª¨ë“  í™œì„±í™”ëœ ìˆ˜ì§‘ê¸° ì‹œì‘")
            
        try:
            await self.collector_manager.start_all(selected_collectors)
        except KeyboardInterrupt:
            print("\nìˆ˜ì§‘ê¸° ì¢…ë£Œ ì¤‘...")
        finally:
            await self.cleanup()
            
    async def start_all(self, args):
        """ì„œë²„ì™€ ìˆ˜ì§‘ê¸° ëª¨ë‘ ì‹œì‘"""
        print("=== í†µí•© ë¡œê·¸ ìˆ˜ì§‘ ì‹œìŠ¤í…œ ì‹œì‘ ===")
        
        config = self.load_config(args.config)
        
        # ì„œë²„ë¥¼ ë³„ë„ í”„ë¡œì„¸ìŠ¤ë¡œ ì‹œì‘
        server_cmd = [
            sys.executable, "-m", "main", "server",
            "--host", args.host or config.server.host,
            "--port", str(args.port or config.server.port),
            "--db", args.db or config.storage.db_path
        ]
        
        if args.config:
            server_cmd.extend(["--config", args.config])
            
        print("ì„œë²„ í”„ë¡œì„¸ìŠ¤ ì‹œì‘ ì¤‘...")
        server_process = subprocess.Popen(server_cmd)
        self.running_processes.append(server_process)
        
        # ì„œë²„ ì‹œì‘ ëŒ€ê¸°
        await asyncio.sleep(3)
        
        if server_process.poll() is not None:
            print("ì„œë²„ ì‹œì‘ ì‹¤íŒ¨")
            return
            
        print("ì„œë²„ ì‹œì‘ë¨, ìˆ˜ì§‘ê¸° ì‹œì‘ ì¤‘...")
        
        # ìˆ˜ì§‘ê¸° ì‹œì‘
        try:
            await self.start_collectors(args)
        finally:
            await self.cleanup()
            
    def init_project(self, args):
        """í”„ë¡œì íŠ¸ ì´ˆê¸°í™”"""
        print("=== í”„ë¡œì íŠ¸ ì´ˆê¸°í™” ===")
        
        project_type = args.type or "webapp"
        project_name = args.name or os.path.basename(os.getcwd())
        
        print(f"í”„ë¡œì íŠ¸ íƒ€ì…: {project_type}")
        print(f"í”„ë¡œì íŠ¸ ì´ë¦„: {project_name}")
        
        # ì„¤ì • íŒŒì¼ ìƒì„±
        config_path = "./log_collector.yaml"
        
        if os.path.exists(config_path) and not args.force:
            print(f"ì„¤ì • íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤: {config_path}")
            if input("ë®ì–´ì“°ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ").lower() != 'y':
                print("ì´ˆê¸°í™” ì·¨ì†Œë¨")
                return
                
        # í”„ë¡œì íŠ¸ íƒ€ì…ë³„ ì„¤ì • ìƒì„±
        config = create_default_config(project_type, project_name)
        
        with open(config_path, 'w', encoding='utf-8') as f:
            yaml.dump(config, f, default_flow_style=False, allow_unicode=True)
            
        print(f"ì„¤ì • íŒŒì¼ ìƒì„±ë¨: {config_path}")
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs("logs", exist_ok=True)
        os.makedirs(".log_collector", exist_ok=True)
        
        # .gitignore ì—…ë°ì´íŠ¸
        gitignore_path = "./.gitignore"
        gitignore_entries = [
            "# Log Collector",
            "logs/",
            "*.db",
            "*.db-*",
            ".log_collector/",
        ]
        
        if os.path.exists(gitignore_path):
            with open(gitignore_path, 'r') as f:
                existing = f.read()
                
            if "# Log Collector" not in existing:
                with open(gitignore_path, 'a') as f:
                    f.write("\n" + "\n".join(gitignore_entries) + "\n")
                print(".gitignore ì—…ë°ì´íŠ¸ë¨")
        else:
            with open(gitignore_path, 'w') as f:
                f.write("\n".join(gitignore_entries) + "\n")
            print(".gitignore ìƒì„±ë¨")
            
        # IDE ì„¤ì • íŒŒì¼ ìƒì„± (VS Code)
        if args.ide == "vscode" or (not args.ide and os.path.exists(".vscode")):
            self._create_vscode_config()
            
        print("\nì´ˆê¸°í™” ì™„ë£Œ!")
        print(f"ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì‹œì‘í•˜ì„¸ìš”:")
        print(f"  python -m main start")
        
    def _create_vscode_config(self):
        """VS Code ì„¤ì • ìƒì„±"""
        vscode_dir = ".vscode"
        os.makedirs(vscode_dir, exist_ok=True)
        
        # settings.json ì—…ë°ì´íŠ¸
        settings_path = os.path.join(vscode_dir, "settings.json")
        settings = {}
        
        if os.path.exists(settings_path):
            try:
                with open(settings_path, 'r') as f:
                    settings = json.load(f)
            except:
                pass
                
        settings.update({
            "log-collector.enabled": True,
            "log-collector.server": "http://localhost:8888",
            "log-collector.auto-start": False
        })
        
        with open(settings_path, 'w') as f:
            json.dump(settings, f, indent=2)
            
        print("VS Code ì„¤ì • ìƒì„±ë¨")
        
    def status(self, args):
        """ì„œë²„ ìƒíƒœ í™•ì¸"""
        config = self.load_config(args.config)
        server_url = f"http://{config.server.host}:{config.server.port}"
        
        print("=== ë¡œê·¸ ìˆ˜ì§‘ê¸° ìƒíƒœ ===")
        print(f"ì„œë²„ URL: {server_url}")
        
        try:
            import requests
            
            # í—¬ìŠ¤ì²´í¬
            health_response = requests.get(f"{server_url}/health", timeout=5)
            if health_response.status_code == 200:
                health_data = health_response.json()
                print(f"âœ… ì„œë²„ ìƒíƒœ: ì •ìƒ")
                print(f"   ì‘ë‹µ ì‹œê°„: {health_data.get('timestamp')}")
                
                # í†µê³„ ì¡°íšŒ
                stats_payload = {
                    "jsonrpc": "2.0",
                    "method": "get_stats",
                    "params": {"timerange": "1h"},
                    "id": 1
                }
                
                stats_response = requests.post(f"{server_url}/rpc", json=stats_payload, timeout=5)
                if stats_response.status_code == 200:
                    stats_data = stats_response.json()
                    if 'result' in stats_data:
                        stats = stats_data['result']
                        print(f"   ì´ ë¡œê·¸: {stats['total_logs']}ê°œ (ìµœê·¼ 1ì‹œê°„)")
                        print(f"   ì†ŒìŠ¤ë³„:")
                        for source, count in stats['by_source'].items():
                            print(f"     - {source}: {count}ê°œ")
                        print(f"   ë ˆë²¨ë³„:")
                        for level, count in stats['by_level'].items():
                            print(f"     - {level}: {count}ê°œ")
                            
            else:
                print(f"âŒ ì„œë²„ ìƒíƒœ: ë¹„ì •ìƒ (HTTP {health_response.status_code})")
                
        except Exception as e:
            print(f"âŒ ì„œë²„ ìƒíƒœ: ì—°ê²° ì‹¤íŒ¨ ({str(e)})")
            
        # ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ
        db_path = config.storage.db_path
        if os.path.exists(db_path):
            db_size = os.path.getsize(db_path) / 1024 / 1024
            print(f"ğŸ’¾ ë°ì´í„°ë² ì´ìŠ¤: {db_path} ({db_size:.1f}MB)")
        else:
            print(f"ğŸ’¾ ë°ì´í„°ë² ì´ìŠ¤: ì—†ìŒ")
            
    def logs(self, args):
        """ë¡œê·¸ ì¡°íšŒ"""
        config = self.load_config(args.config)
        server_url = f"http://{config.server.host}:{config.server.port}/rpc"
        
        # ì¿¼ë¦¬ íŒŒë¼ë¯¸í„° êµ¬ì„±
        params = {
            "limit": args.limit,
        }
        
        if args.source:
            params["sources"] = args.source
        if args.level:
            params["levels"] = args.level
        if args.since:
            params["since"] = args.since
        if args.search:
            # ê²€ìƒ‰ API ì‚¬ìš©
            payload = {
                "jsonrpc": "2.0",
                "method": "search",
                "params": {
                    "query": args.search,
                    "limit": args.limit
                },
                "id": 1
            }
        else:
            payload = {
                "jsonrpc": "2.0", 
                "method": "query",
                "params": params,
                "id": 1
            }
            
        try:
            import requests
            
            response = requests.post(server_url, json=payload, timeout=10)
            if response.status_code == 200:
                data = response.json()
                if 'result' in data:
                    result = data['result']
                    logs = result.get('logs', [])
                    
                    if not logs:
                        print("ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
                        return
                        
                    print(f"=== ë¡œê·¸ ì¡°íšŒ ê²°ê³¼ ({len(logs)}ê°œ) ===")
                    
                    for log in logs:
                        timestamp = log.get('timestamp', '')
                        level = log.get('level', '').ljust(5)
                        source = log.get('source', '').ljust(15)
                        message = log.get('message', '')
                        
                        # ë ˆë²¨ë³„ ìƒ‰ìƒ (í„°ë¯¸ë„ ì§€ì›ì‹œ)
                        if level.strip() == 'ERROR':
                            level_colored = f"\033[91m{level}\033[0m"  # ë¹¨ê°•
                        elif level.strip() == 'WARN':
                            level_colored = f"\033[93m{level}\033[0m"  # ë…¸ë‘
                        elif level.strip() == 'DEBUG':
                            level_colored = f"\033[90m{level}\033[0m"  # íšŒìƒ‰
                        else:
                            level_colored = level
                            
                        print(f"{timestamp[:19]} {level_colored} {source} {message}")
                        
                        # ìƒì„¸ ì •ë³´ í‘œì‹œ
                        if args.verbose:
                            metadata = log.get('metadata', {})
                            if metadata:
                                for key, value in metadata.items():
                                    print(f"    {key}: {value}")
                            print()
                            
                else:
                    print(f"API ì˜¤ë¥˜: {data.get('error', 'Unknown error')}")
            else:
                print(f"HTTP ì˜¤ë¥˜: {response.status_code}")
                
        except Exception as e:
            print(f"ë¡œê·¸ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            
    def migrate(self, args):
        """ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜"""
        print("=== ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜ ===")
        
        old_db = args.from_db
        new_db = args.to_db
        
        if not os.path.exists(old_db):
            print(f"ì›ë³¸ ë°ì´í„°ë² ì´ìŠ¤ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {old_db}")
            return
            
        if os.path.exists(new_db) and not args.force:
            print(f"ëŒ€ìƒ ë°ì´í„°ë² ì´ìŠ¤ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤: {new_db}")
            if input("ë®ì–´ì“°ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ").lower() != 'y':
                print("ë§ˆì´ê·¸ë ˆì´ì…˜ ì·¨ì†Œë¨")
                return
                
        try:
            migrate_database(old_db, new_db)
            print("ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ!")
        except Exception as e:
            print(f"ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {e}")
            
    def daemon(self, args):
        """ë°ëª¬ ëª¨ë“œë¡œ ì‹¤í–‰"""
        print("=== ë°ëª¬ ëª¨ë“œ ì‹œì‘ ===")
        
        # PID íŒŒì¼ ìƒì„±
        pid_file = ".log_collector/daemon.pid"
        os.makedirs(os.path.dirname(pid_file), exist_ok=True)
        
        if os.path.exists(pid_file):
            with open(pid_file, 'r') as f:
                old_pid = f.read().strip()
            print(f"ê¸°ì¡´ ë°ëª¬ì´ ì‹¤í–‰ ì¤‘ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤ (PID: {old_pid})")
            
        with open(pid_file, 'w') as f:
            f.write(str(os.getpid()))
            
        try:
            # ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰
            asyncio.run(self.start_all(args))
        finally:
            if os.path.exists(pid_file):
                os.remove(pid_file)


def create_parser():
    """CLI íŒŒì„œ ìƒì„±"""
    parser = argparse.ArgumentParser(
        description="í†µí•© ë¡œê·¸ ìˆ˜ì§‘ê¸° - ê°œë°œìë¥¼ ìœ„í•œ ì‹¤ì‹œê°„ ë¡œê·¸ ìˆ˜ì§‘ ì‹œìŠ¤í…œ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  %(prog)s init --type webapp                # ì›¹ì•± í”„ë¡œì íŠ¸ ì´ˆê¸°í™”
  %(prog)s start                             # ì„œë²„ì™€ ìˆ˜ì§‘ê¸° ëª¨ë‘ ì‹œì‘
  %(prog)s server --port 9999                # ì„œë²„ë§Œ ì‹œì‘
  %(prog)s collectors --collectors console   # íŠ¹ì • ìˆ˜ì§‘ê¸°ë§Œ ì‹œì‘
  %(prog)s logs --level ERROR --since 1h    # ìµœê·¼ 1ì‹œê°„ ì—ëŸ¬ ë¡œê·¸ ì¡°íšŒ
  %(prog)s status                            # ì„œë²„ ìƒíƒœ í™•ì¸
        """
    )
    
    # ê³µí†µ ì˜µì…˜
    parser.add_argument('--config', help='ì„¤ì • íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--verbose', '-v', action='store_true', help='ìƒì„¸ ì¶œë ¥')
    
    subparsers = parser.add_subparsers(dest='command', help='ëª…ë ¹ì–´')
    
    # init ëª…ë ¹ì–´
    init_parser = subparsers.add_parser('init', help='í”„ë¡œì íŠ¸ ì´ˆê¸°í™”')
    init_parser.add_argument('--type', choices=['webapp', 'api', 'desktop', 'microservice'], 
                           default='webapp', help='í”„ë¡œì íŠ¸ íƒ€ì…')
    init_parser.add_argument('--name', help='í”„ë¡œì íŠ¸ ì´ë¦„')
    init_parser.add_argument('--ide', choices=['vscode', 'pycharm'], help='IDE ì„¤ì • ìƒì„±')
    init_parser.add_argument('--force', action='store_true', help='ê¸°ì¡´ ì„¤ì • ë®ì–´ì“°ê¸°')
    
    # start ëª…ë ¹ì–´ (ê¸°ë³¸)
    start_parser = subparsers.add_parser('start', help='ì„œë²„ì™€ ìˆ˜ì§‘ê¸° ëª¨ë‘ ì‹œì‘')
    start_parser.add_argument('--host', default='0.0.0.0', help='ì„œë²„ í˜¸ìŠ¤íŠ¸')
    start_parser.add_argument('--port', type=int, default=8888, help='ì„œë²„ í¬íŠ¸')
    start_parser.add_argument('--db', help='ë°ì´í„°ë² ì´ìŠ¤ ê²½ë¡œ')
    start_parser.add_argument('--collectors', nargs='*', help='ì‹œì‘í•  ìˆ˜ì§‘ê¸° ëª©ë¡')
    
    # server ëª…ë ¹ì–´
    server_parser = subparsers.add_parser('server', help='ì„œë²„ë§Œ ì‹œì‘')
    server_parser.add_argument('--host', default='0.0.0.0', help='ì„œë²„ í˜¸ìŠ¤íŠ¸')
    server_parser.add_argument('--port', type=int, default=8888, help='ì„œë²„ í¬íŠ¸')
    server_parser.add_argument('--db', help='ë°ì´í„°ë² ì´ìŠ¤ ê²½ë¡œ')
    
    # collectors ëª…ë ¹ì–´
    collectors_parser = subparsers.add_parser('collectors', help='ìˆ˜ì§‘ê¸°ë§Œ ì‹œì‘')
    collectors_parser.add_argument('--collectors', nargs='*', help='ì‹œì‘í•  ìˆ˜ì§‘ê¸° ëª©ë¡')
    
    # status ëª…ë ¹ì–´
    status_parser = subparsers.add_parser('status', help='ì„œë²„ ìƒíƒœ í™•ì¸')
    
    # logs ëª…ë ¹ì–´
    logs_parser = subparsers.add_parser('logs', help='ë¡œê·¸ ì¡°íšŒ')
    logs_parser.add_argument('--source', nargs='*', help='ì†ŒìŠ¤ í•„í„°')
    logs_parser.add_argument('--level', nargs='*', help='ë ˆë²¨ í•„í„°')
    logs_parser.add_argument('--since', help='ì‹œê°„ í•„í„° (ì˜ˆ: 1h, 30m, 1d)')
    logs_parser.add_argument('--search', help='ê²€ìƒ‰ì–´')
    logs_parser.add_argument('--limit', type=int, default=50, help='ì¡°íšŒ ê°œìˆ˜')
    logs_parser.add_argument('--verbose', action='store_true', help='ìƒì„¸ ì •ë³´ í‘œì‹œ')
    
    # migrate ëª…ë ¹ì–´
    migrate_parser = subparsers.add_parser('migrate', help='ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜')
    migrate_parser.add_argument('--from-db', required=True, help='ì›ë³¸ DB ê²½ë¡œ')
    migrate_parser.add_argument('--to-db', required=True, help='ëŒ€ìƒ DB ê²½ë¡œ')
    migrate_parser.add_argument('--force', action='store_true', help='ê¸°ì¡´ DB ë®ì–´ì“°ê¸°')
    
    # daemon ëª…ë ¹ì–´
    daemon_parser = subparsers.add_parser('daemon', help='ë°ëª¬ ëª¨ë“œë¡œ ì‹¤í–‰')
    daemon_parser.add_argument('--host', default='0.0.0.0', help='ì„œë²„ í˜¸ìŠ¤íŠ¸')
    daemon_parser.add_argument('--port', type=int, default=8888, help='ì„œë²„ í¬íŠ¸')
    daemon_parser.add_argument('--db', help='ë°ì´í„°ë² ì´ìŠ¤ ê²½ë¡œ')
    daemon_parser.add_argument('--collectors', nargs='*', help='ì‹œì‘í•  ìˆ˜ì§‘ê¸° ëª©ë¡')
    
    return parser


async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = create_parser()
    args = parser.parse_args()
    
    if not args.command:
        # ê¸°ë³¸ ëª…ë ¹ì–´ëŠ” start
        args.command = 'start'
        
    cli = LogCollectorCLI()
    cli.setup_signal_handlers()
    
    try:
        if args.command == 'init':
            cli.init_project(args)
        elif args.command == 'start':
            await cli.start_all(args)
        elif args.command == 'server':
            await cli.start_server(args)
        elif args.command == 'collectors':
            await cli.start_collectors(args)
        elif args.command == 'status':
            cli.status(args)
        elif args.command == 'logs':
            cli.logs(args)
        elif args.command == 'migrate':
            cli.migrate(args)
        elif args.command == 'daemon':
            cli.daemon(args)
        else:
            parser.print_help()
            
    except KeyboardInterrupt:
        print("\nì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        sys.exit(1)


if __name__ == '__main__':
    asyncio.run(main())
